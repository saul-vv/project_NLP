{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saul\\AppData\\Local\\Temp\\ipykernel_1540\\4077043525.py:1: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/1429_1.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/1429_1.csv\")\n",
    "data_test = pd.read_csv(\"data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "# data_test = pd.read_csv(\"data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.sample(5), data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"categories\",\"reviews.rating\",\"reviews.text\"]]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "data = data.dropna().reset_index()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the test data\n",
    "data_test = data_test[[\"categories\",\"reviews.rating\",\"reviews.text\"]]\n",
    "data_test = data_test.dropna().reset_index()\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Features preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text data\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    Map the results of pos_tag() to the characters that lemmatize() accepts\n",
    "    \"\"\"\n",
    "    # from nltk.corpus import wordnet\n",
    "    tag = nltk.pos_tag([word])[0][1][0]\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def data_cleaning(text):\n",
    "    # import re\n",
    "    # import nltk\n",
    "    # from nltk.corpus import stopwords\n",
    "    # from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^A-Za-z\\s]+', ' ', text) # Regex to remove all the special characters and numbers\n",
    "    text = re.sub(r'\\b\\w\\b', '', text) # Regex to remove all single characters\n",
    "    text = re.sub(r' {2,}', ' ', text).strip() # Regex to substitute multiple spaces with single space\n",
    "    \n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    text = [WordNetLemmatizer().lemmatize(word, get_wordnet_pos(word)) for word in tokenized_text if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    text = \" \".join(text) # Transforms the list of words back into a single string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"reviews.text\"] = data[\"reviews.text\"].apply(data_cleaning)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE CLEAN DATA BACKUP\n",
    "# data.to_csv(\"data_backup.csv\")\n",
    "\n",
    "# data = pd.read_csv(\"data_backup.csv\").dropna()\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Classes preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews.rating\n",
       "Positive    23775\n",
       "Neutral      8541\n",
       "Negative     2311\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reviews.rating\"] = data[\"reviews.rating\"].replace({1: 'Negative', 2: 'Negative', 3: 'Negative', 4: 'Neutral', 5: 'Positive'})\n",
    "data[\"reviews.rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[\"reviews.text\"]\n",
    "# y = data[\"reviews.rating\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[\"reviews.text\"]\n",
    "y_train = data[\"reviews.rating\"]\n",
    "\n",
    "X_test = data_test[\"reviews.text\"].apply(data_cleaning)\n",
    "y_test = data_test[\"reviews.rating\"].replace({1: 'Negative', 2: 'Negative', 3: 'Negative', 4: 'Neutral', 5: 'Positive'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(vectorizer, open(f\"vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "# Grid-Search\n",
    "param_grid = {\n",
    "    'alpha': [0.05, 0.1, 0.2, 0.3],  # Regularization parameter\n",
    "    'fit_prior': [True, False]  # Whether to learn class priors\n",
    "}\n",
    "\n",
    "model = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy')\n",
    "\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters: \", model.best_params_)\n",
    "print(\"Best Score: \", model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(model, open(f\"model_MultinomialNB.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(class_weight=\"balanced\")\n",
    "\n",
    "# # Grid-Search\n",
    "# param_grid = {\n",
    "#     'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "# }\n",
    "\n",
    "# model = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "#                            cv=5, scoring='accuracy')\n",
    "\n",
    "# model.fit(X_train_vec, y_train)\n",
    "\n",
    "# # Print the best parameters and best score\n",
    "# print(\"Best Parameters: \", model.best_params_)\n",
    "# print(\"Best Score: \", model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(model, open(f\"model_SVC.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment')\n",
    "\n",
    "ratings = classifier(X_test.tolist())\n",
    "\n",
    "# Extract the label values into a list\n",
    "predicted_labels_raw = [result['label'].lower() for result in ratings]\n",
    "predicted_labels = list(map(lambda label: 'Negative' if label == 'label_0' else\n",
    "                                      'Neutral' if label == 'label_1' else\n",
    "                                      'Positive' if label == 'label_2' else\n",
    "                                      label, predicted_labels_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(ratings, open(f\"model_TransferLearning.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chosen model\n",
    "best_model = pickle.load(open(\"model_SVC.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.asarray(best_model.predict(X_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix,\n",
    "            annot=True, \n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=[\"Negative\",\"Neutral\",\"Positive\"],\n",
    "            yticklabels=[\"Negative\",\"Neutral\",\"Positive\"],\n",
    "            )\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = {\n",
    "    \"Negative\": {\"precision\": 0.90, \"recall\": 0.84, \"f1-score\": 0.87},\n",
    "    \"Neutral\": {\"precision\": 0.67, \"recall\": 0.81, \"f1-score\": 0.73},\n",
    "    \"Positive\": {\"precision\": 0.92, \"recall\": 0.86, \"f1-score\": 0.89}\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "report = pd.DataFrame(report_dict).T  # Transpose to make classes rows and metrics columns\n",
    "\n",
    "# Plot\n",
    "report.plot(kind=\"bar\", figsize=(10, 8))\n",
    "# plt.title(\"Precision, Recall, and F1-Score by Class\")\n",
    "# plt.xlabel(\"Class\")\n",
    "plt.xticks(rotation=360)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)  # To keep the y-axis within 0-1 range\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
